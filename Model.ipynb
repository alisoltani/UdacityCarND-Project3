{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Behavioral Cloning Project\n",
    "\n",
    "This project will imitate driving with the simulator provided by Udacity. The goal of the project is to drive one lap around the track autonomously, without exiting the track at any point.\n",
    "\n",
    "The user first has to generate test data by driving around the track him/herself, and that data will be used to imitiate the driving patterns using a neural network. The neural network should take the images taken by the simulators cameras and steering data as input/output.\n",
    "\n",
    "The model that is used in this project is based on the NVIDIA model from [here](http://images.nvidia.com/content/tegra/automotive/images/2016/solutions/pdf/end-to-end-dl-using-px.pdf), with some motifications. \n",
    "\n",
    "The model is structured as following, explanations on model structure and preprocessing choices will follow in appropriate sections.\n",
    "\n",
    "| Layer | Description | Output Size         \n",
    "| :-: |:-------------: | :-:\n",
    "|Input | The input data  | input size = (none, 64, 64, 3)\n",
    "| Normalization (lambda) | Normalize data to -1 to 1 | (none, 64, 64, 3)\n",
    "| Conv2D (5,5) | Conv #1  with \"elu\" activation | (none, 60, 60, 24)\n",
    "| Average pooling (2,2) | Pooling layer | (none, 30, 30, 24)\n",
    "| Dropout | 50% | (none, 30, 30, 24)\n",
    "| Conv2D (5,5) | Conv #2 with \"elu\" activation | (none, 26, 26, 36)\n",
    "| Average pooling (2,2) | Pooling layer | (none, 13, 13, 36)\n",
    "| Dropout | 50% | (none, 13, 13, 36)\n",
    "| Conv2D (3,3) | Conv #3 with \"elu\" activation | (none, 11, 11, 48)\n",
    "| Average pooling (2,2) | Pooling layer | (none, 5, 5, 48)\n",
    "| Dropout | 50% | (none, 5, 5, 48)\n",
    "| Conv2D (3,3) | Conv #4 with \"elu\" activation | (none, 3, 3, 64)\n",
    "| Average pooling (2,2) | Pooling layer | (none, 1, 1, 64)\n",
    "| Dropout | 50% | (none, 1, 1, 64)\n",
    "| Flatten | Make fully connected | (none, 64)\n",
    "| Dense | Fully connected | (none, 50)\n",
    "| Dropout | 50% | (none, 50)\n",
    "| Dense | Fully connected | (none, 10)\n",
    "| Dropout | 50% | (none, 10)\n",
    "| Dense | Output (steering) | (none, 1)\n",
    "\n",
    "\n",
    "Instead of the (2,2) strides in the original NVIDIA model, I have used (2,2) average pooling layers, and have also added a dropout layer afterwards for each layer, to prevent overfitting. The original model size and layers were changed due to using 64 by 64 pixel images instead of 66 by 200 from the paper.\n",
    "\n",
    "This can also be seen from the plot(model) output from Keras ![here](model.png \"CNN model used for behavioral cloning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import ntpath\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First step is to import and  process the data from the driver in the simulator\n",
    "\n",
    "For this project, I have used the data provided by Udacity and supplemented it with additional data taken on curves and on the bridge, and some data on how to recover from bad initial position (close to the edge of the road).\n",
    "\n",
    "First we need to pre-process the data. Ideally this should/could be done within the model structure, but due to some difficulties and bugs the training data was affected but not during run time in the drive.py file. So instead the pre-processing was done outside the main model, and added to the drive.py funciton as well.\n",
    "\n",
    "In the pre-processing phase, threes steps are done. This step proved to be quite crucial and changing the model structure had less impact than the preprocessing did.\n",
    "\n",
    "* Change the image from rgb to yuv\n",
    "\n",
    "    This comes from the NVIDIA model and helps to de-correlate the images three colors to make the most of the data we have.\n",
    "    \n",
    "\n",
    "* Crop image\n",
    "\n",
    "    This is done to remove the unneeded data regarding the sky and trees in the horizon, so we don't spend modeling effort on them.\n",
    "    \n",
    "\n",
    "* Resize image\n",
    "\n",
    "    This is done to reduce the memory burdeon of the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_image(img):\n",
    "\tyuvImg = cv2.cvtColor(img, cv2.COLOR_BGR2YUV)\n",
    "\tcroppedImg = yuvImg[60:150, 0:360]\n",
    "\treturn cv2.resize(croppedImg, (64,64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since I have data originaing from both Linux and Windows machines, and the path format varies between these two environments, the process_files function takes the path and IsWindows as arguments. It also takes an additional argument to determine if the data should be flipped (horizontally) or not. This is done to reduce the dependency on the current track and its relative left curves.\n",
    "\n",
    "Data from all three cameras on the car are used, and a steering correction of 0.25 is applied to the steering vector to compensate for the left and right camera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_files(IsWindows=False, originalpath='data/', flip=False):\n",
    "\tlines = []\n",
    "\twith open(originalpath + 'driving_log.csv') as csvfile:\n",
    "\t\treader = csv.reader(csvfile)\n",
    "\t\tnext(reader)\n",
    "\t\tfor line in reader:\n",
    "\t\t\tlines.append(line)\n",
    "        \n",
    "\tcar_camera_images = []\n",
    "\tsteering_angles = []\n",
    "\n",
    "\tsteering_correction = 0.25\n",
    "\n",
    "\tfor line in lines:\n",
    "\t\tsource_path = line[0]\n",
    "\t\tif IsWindows:\n",
    "\t\t\tdrive, path_and_file = ntpath.splitdrive(source_path)\n",
    "\t\t\tpath, filename = ntpath.split(path_and_file)\n",
    "\t\telse:\n",
    "\t\t\tfilename = source_path.split('/')[-1]\n",
    "\t\t\t\n",
    "\t\tleft_filename = filename.replace('center', 'left')\n",
    "\t\tright_filename = filename.replace('center', 'right')\n",
    "\t\t\n",
    "\t\tcenter_path = originalpath + 'IMG/' + filename\n",
    "\t\tleft_path = originalpath + 'IMG/' + left_filename\n",
    "\t\tright_path = originalpath + 'IMG/' + right_filename\n",
    "\t\t\n",
    "\t\timage_center = cv2.imread(center_path)\n",
    "\t\timage_left = cv2.imread(left_path)\n",
    "\t\timage_right = cv2.imread(right_path)\n",
    "\n",
    "\t\tif flip:\n",
    "\t\t\timage_center = cv2.flip(image_center, 0)\n",
    "\t\t\timage_left = cv2.flip(image_left,0)\n",
    "\t\t\timage_right = cv2.flip(image_right,0)\n",
    "\t\t\n",
    "\t\tsteering_angle = float(line[3])\n",
    "\t\tsteering_left = steering_angle + steering_correction\n",
    "\t\tsteering_right = steering_angle - steering_correction\n",
    "\t\t\n",
    "\t\tif flip:\n",
    "\t\t\tsteering_angle = -steering_angle\n",
    "\t\t\tsteering_left = -steering_left\n",
    "\t\t\tsteering_right = -steering_right\n",
    "\n",
    "\t\timage_center = process_image(image_center)\n",
    "\t\timage_left = process_image(image_left)\n",
    "\t\timage_right = process_image(image_right)\n",
    "\t\t\n",
    "\t\tcar_camera_images.extend([image_center, image_left, image_right])\n",
    "\t\tsteering_angles.extend([steering_angle, steering_left, steering_right])\n",
    "\t\t\n",
    "\treturn car_camera_images, steering_angles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the data is loaded and processed. There are 4 sets of data, the original data from Udacity, MyOwnData3 and MyOwnData4 which focus on curves, the bridge, and recovering from bad position on the road, and MyOwnData2 which is just a normal run as close to center as possible and flipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the image data is (47250, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "car_camera_images, steering_angles = process_files(IsWindows=False, originalpath='data/', flip=False)\n",
    "\n",
    "car_camera_images_windows, steering_angles_windows = process_files(IsWindows=True, originalpath='MyOwnData3/', flip=False)\n",
    "car_camera_images = car_camera_images + car_camera_images_windows\n",
    "steering_angles = steering_angles + steering_angles_windows\n",
    "\n",
    "car_camera_images_windows, steering_angles_windows = process_files(IsWindows=True, originalpath='MyOwnData4/', flip=False)\n",
    "car_camera_images = car_camera_images + car_camera_images_windows\n",
    "steering_angles = steering_angles + steering_angles_windows\n",
    "\n",
    "car_camera_images_windows, steering_angles_windows = process_files(IsWindows=True, originalpath='MyOwnData2/', flip=True)\n",
    "car_camera_images = car_camera_images + car_camera_images_windows\n",
    "steering_angles = steering_angles + steering_angles_windows\n",
    "\n",
    "X_train = np.array(car_camera_images)\n",
    "y_train = np.array(steering_angles)\n",
    "\n",
    "print('The shape of the image data is', X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Net model \n",
    "The model follows the structure presented before, and uses an \"elu\" activation instead of \"relu\" to help with smaller steering values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Lambda, Conv2D, Dropout, Cropping2D\n",
    "from keras.layers.pooling import MaxPooling2D, AveragePooling2D\n",
    "\n",
    "## Inspired from the NVIDIA model\n",
    "model = Sequential()\n",
    "model.add(Lambda(lambda x: (x/127.5) - 1, input_shape = (64,64,3)))\n",
    "#model.add(Cropping2D(cropping=((60,10),(0,0))))\n",
    "model.add(Conv2D(24, 5, 5, activation='elu', border_mode='valid'))\n",
    "model.add(AveragePooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(36, 5, 5, activation='elu', border_mode='valid'))\n",
    "model.add(AveragePooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(48, 3, 3, activation='elu', border_mode='valid'))\n",
    "model.add(AveragePooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv2D(64, 3, 3, activation='elu', border_mode='valid'))\n",
    "model.add(AveragePooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='elu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='elu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile and train the model\n",
    "For this model, I chose the nadam optimizer instead of the adam optimizer, as it incorporates Nesterov momentum into Adam optimizer and has faster convergent [[1]](http://cs229.stanford.edu/proj2015/054_report.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer='nadam')\n",
    "model.fit(X_train, y_train, validation_split=0.2, shuffle=True, nb_epoch=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save and plot the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.save('model.h5')\n",
    "plot(model, to_file='model.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
